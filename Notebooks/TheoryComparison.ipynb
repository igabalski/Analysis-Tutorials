{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic iPython command to enable plotting\n",
    "%matplotlib inline\n",
    "\n",
    "experiment='cxilu9218'\n",
    "# experiment='cxix38318'\n",
    "pullDataFromUser='igabalsk' # update me to mrware or igablsk\n",
    "RESULTSPATH=('/cds/data/psdm/%s/%s/results/%s' % (experiment[0:3],experiment,pullDataFromUser)).strip()\n",
    "# Load in the pythonBatchMagic |library\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load point data from pkl (preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "def load_obj(filename ):\n",
    "    \"\"\"\n",
    "    Loads object from name.pkl and returns its value\n",
    "\n",
    "    Args:\n",
    "        filename: String designating directory and name of file, ie. /Folder/Filename, where Filename.pkl is the object\n",
    "\n",
    "    Returns:\n",
    "        The value of the object in filename\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename + '.pkl', 'rb') as f:\n",
    "            print filename+\" remembered!\"\n",
    "            return pickle.load(f)\n",
    "    except IOError as e:\n",
    "        print \"IOError: Did you load the correct file? %s\" % filename\n",
    "        raise e\n",
    "def save_obj(obj, filename ):\n",
    "    \"\"\"\n",
    "    Saves object from filename.pkl\n",
    "\n",
    "    Args:\n",
    "        obj: The python object to save\n",
    "        filename: String designating directory and name of file, ie. /Folder/Filename, where Filename.pkl is the object\n",
    "    \"\"\"\n",
    "    with open(filename + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "exclude_keys = ['Qs','phis','bin_sizes']\n",
    "\n",
    "def combineRuns(runNumbers, path=RESULTSPATH, prefix='all'):\n",
    "    detArrays = {}\n",
    "    for idx,run in enumerate(runNumbers):\n",
    "        if idx == 0:\n",
    "            detArrays = load_obj(path+'/%sData-run-%d' % (prefix,run))\n",
    "        else:\n",
    "            try:\n",
    "                detArrays0 = load_obj(path+'/%sData-run-%d' % (prefix,run))\n",
    "                for key in detArrays.keys():\n",
    "                    if key in exclude_keys:\n",
    "                        continue\n",
    "                    try:\n",
    "                        detArrays[key] = np.append( detArrays[key], detArrays0[key], axis=0 )\n",
    "                    except KeyError as ke:\n",
    "                        print('Dropping key %s since it is not in %d' % (key,run))\n",
    "                        detArrays.pop(key, None)\n",
    "            except IOError as ioe:\n",
    "                print(str(ioe))\n",
    "                continue\n",
    "    return detArrays\n",
    "\n",
    "def downsampleRun(runNumber, path=RESULTSPATH):\n",
    "    detArrays = load_obj(path+'/allData-run-%d' % runNumber)\n",
    "    bin_sizes = detArrays['bin_sizes']\n",
    "    qphirois = detArrays['qphirois']\n",
    "    qphirois[np.isnan(qphirois)] = 0\n",
    "    qbin_weights = np.repeat(np.expand_dims(bin_sizes,axis=0),len(qphirois),axis=0)\n",
    "    rois = np.average(qphirois,axis=-1,weights=qbin_weights)\n",
    "    allIdx = np.ones_like(detArrays['seconds']).astype(bool)\n",
    "    newdetArrays = {}\n",
    "    exclude_keys = ['qphirois','Qs','phis','bin_sizes']\n",
    "    for key in detArrays.keys():\n",
    "        if key in exclude_keys:\n",
    "            continue\n",
    "        try:\n",
    "            newdetArrays[key]= np.copy(detArrays[key][allIdx,:])\n",
    "        except IndexError as ie:\n",
    "            newdetArrays[key]= np.copy(detArrays[key][allIdx] )\n",
    "    newdetArrays['rois'] = np.copy(rois[allIdx,:])\n",
    "    newdetArrays['Qs'] = np.copy(detArrays['Qs'])\n",
    "    newdetArrays['bin_sizes'] = np.sum(detArrays['bin_sizes'],axis=-1)\n",
    "        \n",
    "    save_obj( newdetArrays, path +'/filteredData-run-%d' % runNumber )\n",
    "    np.savez(path +'/filteredData-run-%d' % runNumber, **newdetArrays)\n",
    "    import h5py\n",
    "    with h5py.File(path +'/filteredData-run-%d.h5' % runNumber,'w') as f:\n",
    "        for key in newdetArrays.keys():\n",
    "            f.create_dataset(key,data=np.array(newdetArrays[key]).astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runNumbers = [45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,]#61,62,63,64,]#65,67,68,69,70,71] # day 1\n",
    "# runNumbers = [91,92,93,94,95,96,97,98,99,100,] # day 2\n",
    "# runNumbers = [121,122,123,124,125,126,127,128,129,130,131]\n",
    "runNumbersRange = '[%d - %d]' % (min(runNumbers),max(runNumbers))\n",
    "\n",
    "detArrays = combineRuns(runNumbers,prefix='filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([ 2.94720875e-06, -1.36213787e-03]) # LV11\n",
    "p = np.array([2.95684259e-06, -1.43969413e-03])  # LU92\n",
    "p = np.array([-9.36209506e-10,  3.76314033e-06, -1.63476074e-03]) # LU92 quadratic fit\n",
    "pos0 = 80.554 # LV11\n",
    "pos0 = 56.35 # LU92\n",
    "stage_fs = -2*(detArrays['stageencoder']-pos0) / (3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radiial rois vs. pixel and vs. Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = detArrays['Qs']\n",
    "print detArrays['rois'].shape\n",
    "plt.figure()\n",
    "meanSig = np.nanmean(detArrays['rois'][1:,],0)\n",
    "plt.plot(Q,Q*meanSig)\n",
    "plt.xlabel('Q')\n",
    "plt.ylabel('Q * I(Q)')\n",
    "plt.show()\n",
    "goodQIdx = np.concatenate((np.array([1.0]),np.diff(meanSig)<0.0001))\n",
    "goodQIdx[goodQIdx==0]=np.nan\n",
    "filteredrois = goodQIdx*detArrays['rois']\n",
    "meanSig = np.nanmean(filteredrois,0)\n",
    "plt.plot(Q,Q*meanSig)\n",
    "plt.xlabel('Q')\n",
    "plt.ylabel('Q * I(Q)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply detector response function to the average scattering pattern and compare to the theoretical signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizedPlot(x,y,s=1,**kwargs):\n",
    "    plt.semilogy(x, y/np.nanmean(y[(x>1)&(x<2.5)])*s,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def loadfile(filename):\n",
    "    mol = {}\n",
    "    with h5py.File(filename,'r') as f:\n",
    "        for name, data in f.items():\n",
    "            mol[name]=f[name][()]\n",
    "            print name\n",
    "    return mol\n",
    "\n",
    "molecule = 'CS2'\n",
    "mol = loadfile('/cds/home/i/igabalsk/xray/diffraction_simulation/isotropic_scattering_%s.h5' % molecule)\n",
    "\n",
    "interpolatedMol = np.interp(Q, mol['QQ_1d'], mol['isotropic_scattering_1d'])\n",
    "\n",
    "normalizedPlot(Q,meanSig,s=1)\n",
    "normalizedPlot(Q,interpolatedMol)\n",
    "# plt.savefig('masked_mean_withresponse.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From seconds, nanoseconds, and fiducials generate the labtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.dates as dates\n",
    "def getLabtime(second, microseconds):\n",
    "    refdate = datetime.datetime(1970,1,1)\n",
    "    td = datetime.timedelta(seconds=second,microseconds=microseconds)\n",
    "    return refdate+td\n",
    "labtime = np.array([getLabtime( s, float(ns)/1000. ) for s,ns in zip(detArrays['seconds'],detArrays['nanoseconds'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier rejection and time binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodIdx = ( detArrays['xrayEnergy']>.2 ) \n",
    "goodIdx = goodIdx & (np.nansum(detArrays['rois'],-1) > 0.01) \n",
    "goodIdx = goodIdx & (~np.isnan(detArrays['uvint1'])) \n",
    "goodIdx = goodIdx & ( detArrays['xrayOn'].astype(bool))\n",
    "offIdx = goodIdx & (~detArrays['laserOn'].astype(bool))\n",
    "goodIdx = goodIdx & ( detArrays['laserOn'].astype(bool))\n",
    "\n",
    "dp=75\n",
    "goodIdx = goodIdx &( (detArrays['ttfltpos']>500-dp)  & (detArrays['ttfltpos']<500+dp)  )\n",
    "goodIdx = goodIdx &( (detArrays['ttfltposfwhm']>5) )\n",
    "goodIdx = goodIdx &( (detArrays['ttfltposampl']>.005) )\n",
    "\n",
    "pos = detArrays['stageencoder'][goodIdx] \n",
    "ttpos = detArrays['ttfltpos'][goodIdx]\n",
    "goodRois = detArrays['rois'][goodIdx,:]\n",
    "offRois =  detArrays['rois'][offIdx,:]\n",
    "print 'Good shots:',np.sum(goodIdx>0)\n",
    "print 'Total shots:',detArrays['ttfltpos'].size\n",
    "\n",
    "ttpoly = [2.95684259e-06, -1.43969413e-03] # LV11\n",
    "ttpoly = [2.95684259e-06, -1.43969413e-03] # LU92\n",
    "ttpoly = [-9.36209506e-10,  3.76314033e-06, -1.63476074e-03] # LU92 quadratic fit\n",
    "def ttcorr(ttpos,ttpoly):\n",
    "    return ttpoly[0]*ttpos**2+ttpoly[1]*ttpos+ttpoly[2]\n",
    "truepos = -2*(pos-pos0) / (3e-4)  - ttcorr(ttpos,ttpoly)*1.0e6\n",
    "posfs = -2*(pos-pos0) / (3e-4) \n",
    "\n",
    "roio = np.nansum(offRois,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the radial rois by normalizing by xray energy and subtracting the nearest off shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeWeights( rois, goodIdx, offIdx, labtime, subNearest=0 ):\n",
    "    offtime = labtime[offIdx]\n",
    "    goodtime = labtime[goodIdx]\n",
    "    offrois = rois[offIdx,:]\n",
    "    goodrois = rois[goodIdx,:]\n",
    "    \n",
    "    osum = np.nansum(offrois,-1)\n",
    "    offroiN = ((offrois.T)/(osum.T)).T\n",
    "    gsum = np.nansum(goodrois,-1)\n",
    "    groiN = ((goodrois.T)/(gsum.T)).T\n",
    "    \n",
    "    offDelta = offtime-datetime.datetime(1970,1,1)\n",
    "    offDelta_s = np.array([dt.total_seconds() for dt in offDelta])\n",
    "    offArg = np.argsort( offDelta_s )\n",
    "    offMin = np.min(offDelta_s)\n",
    "    offMax = np.max(offDelta_s)\n",
    "    offRange = offMax-offMin\n",
    "    noff = offtime.size\n",
    "    \n",
    "    offroiNS = offroiN[offArg,:]\n",
    "    \n",
    "    weights = np.zeros_like(goodrois)\n",
    "    for idx,atime in enumerate(goodtime):\n",
    "#         print(idx,goodtime.size)\n",
    "        dtime =( atime-datetime.datetime(1970,1,1)).total_seconds()\n",
    "        oidx = int((dtime - offMin)/offRange*noff)\n",
    "        if oidx < 0:\n",
    "            oidx = 0\n",
    "        if oidx >= noff:\n",
    "            oidx = noff-1\n",
    "        weights[idx,:] = groiN[idx,:] - subNearest*offroiNS[oidx,:]\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightMe = makeWeights( detArrays['rois'], goodIdx, offIdx, labtime, subNearest=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebin the shot-by-shot data into time bins (without timetool correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 1e-2\n",
    "bins = np.unique(pos) - db\n",
    "bins = np.append(bins, bins[-1]+ 2*db)\n",
    "nb = bins.size\n",
    "nr = goodRois.shape[1]\n",
    "\n",
    "def createBinsFromCenters(centers):\n",
    "    bins = []\n",
    "    nc = centers.size\n",
    "    for idx,c in enumerate(centers):\n",
    "        if idx == 0:\n",
    "            dc = np.abs( c - centers[idx+1])/2.\n",
    "            bins.append(c-dc)\n",
    "            bins.append(c+dc)\n",
    "        elif idx == nc-1:\n",
    "            dc = np.abs( c - centers[idx-1])/2.\n",
    "            bins.append(c+dc)\n",
    "        else:\n",
    "            dc = np.abs( c - centers[idx+1])/2.\n",
    "            bins.append(c+dc)\n",
    "#         print(dc)\n",
    "    return np.array(bins)\n",
    "\n",
    "def determineGoodCenters( pos ):\n",
    "    upos = np.unique(pos)\n",
    "    gpos = []\n",
    "    for idx,up in enumerate(upos):\n",
    "        c = np.sum(upos == up)\n",
    "        if c>10:\n",
    "            gpos.append()\n",
    "        \n",
    "bins = createBinsFromCenters(  np.sort(np.unique( np.round(pos,decimals=2),axis=None)).flatten())\n",
    "centers = np.sort(np.unique(np.round(pos,decimals=2),axis=None)).flatten()\n",
    "centersfs = 2*np.flip(np.array(centers)-pos0) / (3e-4)\n",
    "# bins = np.append(bins, 80.73)\n",
    "binspos = bins\n",
    "# print(bins)\n",
    "nb = bins.size\n",
    "# weightMe = ((goodRois.T)/(roi1.T)).T\n",
    "# weightMe = (goodRois)\n",
    "print(pos.size)\n",
    "print(weightMe.shape)\n",
    "\n",
    "radialHist = np.zeros((nb-1,nr))\n",
    "radialAvg = np.zeros((nb-1,nr))\n",
    "\n",
    "counts,edges = np.histogram( pos,bins=bins)\n",
    "for ir in range(nr):\n",
    "\n",
    "    radialHist[:,ir],edges = np.histogram( pos,bins=bins, weights=weightMe[:,ir])\n",
    "    radialAvg[:,ir] = radialHist[:,ir] / counts\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the timebin centers and the number of events in each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = np.sort(np.unique(np.round(pos,decimals=2),axis=None)).flatten()\n",
    "centerspos = centers\n",
    "plt.figure()\n",
    "# plt.plot(-2*(centers-t0_nominal) / (3e-4), counts)\n",
    "plt.plot(centers, counts,'.-')\n",
    "plt.xlabel('delay pos')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update cutoff to reflect bad points above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2d= (radialAvg)[counts>cutoff,:] #/avgAll\n",
    "\n",
    "rcent = centers[counts>cutoff]\n",
    "rcentfs = -2*(rcent-pos0) / (3e-4)\n",
    "# subAll = np.mean( plot2d[:,:], 0 ) # subtract first 3 delays\n",
    "# avgAll = np.mean( plot2d[-2:,:][:,:], 0 ) # subtract first 3 delays\n",
    "# subAll = np.mean( plot2d[:,:], 0 )\n",
    "subAll = np.mean(((offRois.T)/(roio.T)).T,0) # goose subtraction\n",
    "avgAll = np.mean(((offRois.T)/(roio.T)).T,0)\n",
    "# plot2d = (plot2d-subAll) /avgAll\n",
    "\n",
    "gf = lambda x: gaussian_filter1d(x,2,axis=-1)\n",
    "plot2d = (gf(plot2d)-gf(subAll)) / gf(avgAll)\n",
    "plot2d = gaussian_filter1d(plot2d,1,axis=0)\n",
    "# plot2d = (plot2d-subAll) / avgAll\n",
    "\n",
    "dv = 4e-3\n",
    "# dv = 1e-5\n",
    "# dv = .001\n",
    "# qs = x/ 31578.94736842 * 3.5\n",
    "print Q.shape, rcent.shape, plot2d.shape\n",
    "plt.pcolormesh(Q, rcentfs , plot2d, vmin = -dv, vmax = dv )\n",
    "\n",
    "\n",
    "# plt.pcolormesh(Q, -2*(rcent-pos0) / (3e-4) , plot2d)#, vmin = -dv, vmax = dv )\n",
    "\n",
    "# plt.pcolormesh(Q, rcent, plot2d)#, vmin = -dv, vmax = dv )\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlabel('Q (iA)')\n",
    "plt.ylabel('delay (fs)')\n",
    "plt.title('(I - I(off) )/I(off)')\n",
    "# plt.savefig('/cds/home/m/mrware/Documents/cxix38318-run37.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "runNumbersRange = '[%d - %d]' % (min(runNumbers),max(runNumbers))\n",
    "for idx,delay in enumerate(rcentfs):\n",
    "    plt.plot(Q, plot2d[idx,:], label='%.2f ps'% (delay/1000),linewidth=2 )\n",
    "plt.ylim([-.015,.015])\n",
    "plt.xlabel('Q',fontsize=20)\n",
    "plt.ylabel('dI/I',fontsize=20)\n",
    "plt.title('Day 1: Runs %s'%runNumbersRange,fontsize=20)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both',length=5,width=2,labelsize=15)\n",
    "# ax = fig.add_axes([1,0, 0.6, 0.75])\n",
    "plt.legend(fontsize=15,bbox_to_anchor=(1, 1), loc='upper left',ncol=2)\n",
    "# plt.savefig('day 1 lineout signal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat with timetool correction\n",
    "\n",
    "Specify the centers you'd like to use for timetool bining\n",
    "\n",
    "Histogram shows the number of counts in each bin you'll generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttpoly = [2.95684259e-06, -1.43969413e-03]\n",
    "ttpoly = np.array([ 2.94720875e-06, -1.36213787e-03])\n",
    "ttpoly = [-9.36209506e-10,  3.76314033e-06, -1.63476074e-03] # LU92 quadratic fit\n",
    "def ttcorr(ttpos,ttpoly):\n",
    "    return ttpoly[0]*ttpos**2+ttpoly[1]*ttpos+ttpoly[2]\n",
    "\n",
    "truepos = -2*(pos-pos0) / (3e-4)  + ttcorr(ttpos,ttpoly)*1.0e6 # correct\n",
    "# truepos = -2*(pos-pos0) / (3e-4)  - ttcorr(ttpos,ttpoly)*1.0e6 # wrong\n",
    "posfs = -2*(pos-pos0) / (3e-4) \n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.hist(truepos,bins=1000)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both',length=5,width=2,labelsize=15)\n",
    "plt.xlabel('pump-probe delay (fs)',fontsize=20)\n",
    "plt.ylabel('frames in timebin',fontsize=20)\n",
    "# plt.xlim([-10000,10000])\n",
    "# plt.xlim([-1400,1200])\n",
    "plt.title('pump-probe delay histogram')\n",
    "\n",
    "plt.title('Runs %s'%runNumbersRange,fontsize=20)\n",
    "# usecenters = np.array([3000,2000])\n",
    "usecenters =  np.arange(-1500,500,15)\n",
    "# usecenters = np.concatenate((np.array([-2000,-1000]),usecenters,np.array([2000,3000,4000,5000])))\n",
    "# usecenters = np.append(usecenters,np.array([-2500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 1e-3\n",
    "bins = np.unique(pos) - db\n",
    "bins = np.append(bins, bins[-1]+ 2*db)\n",
    "nb = bins.size\n",
    "nr = goodRois.shape[1]\n",
    "\n",
    "def createBinsFromCenters(centers):\n",
    "    bins = []\n",
    "    nc = centers.size\n",
    "    for idx,c in enumerate(centers):\n",
    "        if idx == 0:\n",
    "            dc = np.abs( c - centers[idx+1])/2.\n",
    "            bins.append(c-dc)\n",
    "            bins.append(c+dc)\n",
    "        elif idx == nc-1:\n",
    "            dc = np.abs( c - centers[idx-1])/2.\n",
    "            bins.append(c+dc)\n",
    "        else:\n",
    "            dc = np.abs( c - centers[idx+1])/2.\n",
    "            bins.append(c+dc)\n",
    "#         print(dc)\n",
    "    return np.array(bins)\n",
    "\n",
    "def determineGoodCenters( pos ):\n",
    "    upos = np.unique(pos)\n",
    "    gpos = []\n",
    "    for idx,up in enumerate(upos):\n",
    "        c = np.sum(upos == up)\n",
    "        if c>10:\n",
    "            gpos.append()\n",
    "        \n",
    "# bins = np.flip(-2*(createBinsFromCenters(  np.round(usecenters,decimals=2) )-56.35)/(3.0e-4))\n",
    "# centersfs = np.flip(-2*(np.round(usecenters,decimals=2)-56.35)/(3.0e-4))\n",
    "\n",
    "bins = createBinsFromCenters( np.array(usecenters) )\n",
    "\n",
    "centersfs = usecenters\n",
    "\n",
    "#### use rough times\n",
    "# bins = np.flip(-2*(binspos-56.35)/(3.0e-4))\n",
    "# centersfs = -2*(centerspos-56.35)/(3.0e-4)\n",
    "\n",
    "# print(bins)\n",
    "# -(pos-56.35) / (3e-4) \n",
    "nb=bins.size\n",
    "# weightMe = ((goodRois.T)/(roi1.T)).T\n",
    "print(weightMe.shape, truepos.shape)\n",
    "\n",
    "radialHist = np.zeros((nb-1,nr))\n",
    "radialAvg = np.zeros((nb-1,nr))\n",
    "counts,edges = np.histogram( truepos,bins=bins)\n",
    "for ir in range(nr):\n",
    "\n",
    "    radialHist[:,ir],edges = np.histogram( truepos,bins=bins, weights=weightMe[:,ir])\n",
    "    radialAvg[:,ir] = radialHist[:,ir] / counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 300\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(centersfs, counts,'.-',linewidth=2,markersize=10)\n",
    "# print(centersfs).-\n",
    "plt.ylim([cutoff,np.max(counts)+500])\n",
    "plt.xlabel('binned delay (fs)',fontsize=20)\n",
    "plt.ylabel('counts in bin',fontsize=20)\n",
    "plt.title('Runs %s'%runNumbersRange,fontsize=20)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both',length=5,width=2,labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2d= (radialAvg)[counts>cutoff,:] #/avgAll\n",
    "#normalize each time bin\n",
    "\n",
    "rcent=centersfs[counts>cutoff]\n",
    "subAll = np.mean( plot2d[:5,:], 0 )\n",
    "# subAll = np.mean( plot2d[:,:], 0 )\n",
    "# avgAll = np.mean( plot2d[:,:], 0 )\n",
    "avgAll = np.mean(((offRois.T)/(roio.T)).T,0)\n",
    "subAll = np.mean(((offRois.T)/(roio.T)).T,0)\n",
    "# plot2d = (plot2d-subAll) #/avgAll\n",
    "# dv = .0001\n",
    "# plot2d = (plot2d-subAll) /avgAll\n",
    "\n",
    "gf_q = lambda x: gaussian_filter1d(x,3,axis=-1)\n",
    "gf_t = lambda x: gaussian_filter1d(x,0.7,axis=0)\n",
    "plot2d = (gf_q(plot2d)-gf_q(subAll)) /gf_q(avgAll)\n",
    "plot2d = gf_t(plot2d)\n",
    "# plot2d = gaussian_filter1d(plot2d,1,axis=0)\n",
    "\n",
    "# dv = 1e\n",
    "dv = .005\n",
    "# dv = .01\n",
    "# qs = x/ 31578.94736842 * 3.5\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.pcolormesh(Q, rcent, plot2d, vmin = -dv, vmax = dv )\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(length=5,width=2,labelsize=15)\n",
    "plt.xlabel('Q (iA)',fontsize=20)\n",
    "plt.ylabel('delay (fs)',fontsize=20)\n",
    "plt.title('(I - I(off))/I(off) (with timetool)',fontsize=20)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both',length=5,width=2,labelsize=15)\n",
    "# plt.savefig('day 1 colorplot signal.png')\n",
    "plt.xlim([0.5,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal fourier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridx=(rcent>-700)&(rcent<=1100)\n",
    "\n",
    "for2dfft =plot2d[ridx,:]\n",
    "for2dfft = for2dfft - np.mean(for2dfft,0)\n",
    "fftall = np.fft.fftshift(np.fft.fft(for2dfft , axis=0 ),axes=(0,))\n",
    "ws = np.fft.fftshift(np.fft.fftfreq(n=for2dfft.shape[0],d=(rcent[1]-rcent[0])/1000.))*2*np.pi\n",
    "dw = ws[2]-ws[1]\n",
    "\n",
    "blur_f = 2\n",
    "gf_f = lambda x: gaussian_filter1d(np.real(x),blur_f,axis=0)+1.0j*gaussian_filter1d(np.imag(x),blur_f,axis=0)\n",
    "fftfilt = gf_f(fftall)\n",
    "QQ,WW = np.meshgrid(Q,ws)\n",
    "plt.pcolormesh(Q,ws,np.abs(WW)*np.abs(fftfilt)**2)\n",
    "plt.colorbar()\n",
    "plt.clim([0,3e-2])\n",
    "plt.xlim([0.5,4])\n",
    "plt.xlabel('Q (iA)')\n",
    "plt.ylabel('w (rad-THz)')\n",
    "plt.title('FT(dI/I) for runs '+str(runNumbersRange))\n",
    "plt.show()\n",
    "print fftfilt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import lombscargle\n",
    "def get_lombscargle(Qs, ts, signal):\n",
    "    omegas = np.fft.fftshift(np.fft.fftfreq(n=ts.size,d=np.mean(np.diff(ts))) )*2*np.pi\n",
    "    goodOmegas = omegas[omegas>0]\n",
    "    goodOmegas = np.linspace(np.min(goodOmegas),1*np.max(goodOmegas),len(goodOmegas))\n",
    "    output = np.zeros((2*goodOmegas.size,Qs.size))\n",
    "    nw = len(goodOmegas)\n",
    "    for qIdx, q in enumerate(Qs):\n",
    "        output[nw:,qIdx] = lombscargle(ts,signal[:,qIdx],goodOmegas,precenter=True)\n",
    "        output[:nw,qIdx] = np.flip(output[nw:,qIdx],axis=0)\n",
    "    return 1000*np.concatenate((-1*np.flip(goodOmegas),goodOmegas)), output\n",
    "\n",
    "ridx=(rcent>-600)&(rcent<=400)\n",
    "for2dfft =plot2d[ridx,:]\n",
    "for2dfft = for2dfft - np.mean(for2dfft,0)\n",
    "fftall = np.fft.fftshift(np.fft.fft(for2dfft , axis=0 ),axes=(0,))\n",
    "omegas_ls, ls = get_lombscargle(Q,rcent[ridx],plot2d[ridx,:])\n",
    "\n",
    "# omegas_ls = omegas_ls-np.mean(np.diff(omegas_ls))/2\n",
    "QQ,WW_ls = np.meshgrid(Q,omegas_ls)\n",
    "\n",
    "blur_ls = 1\n",
    "gf_ls = lambda x: gaussian_filter1d(x,blur_ls,axis=0)\n",
    "ls_filt = gf_ls(ls)\n",
    "plt.figure()\n",
    "plt.pcolormesh(Q,omegas_ls,np.abs(WW_ls)*ls_filt)\n",
    "# plt.ylim([-90,90])\n",
    "plt.xlim([0.5,4])\n",
    "plt.clim([0,1e-4])\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'Q ($\\AA^{-1}$)')\n",
    "plt.ylabel(r'$\\omega$ (rad THz)')\n",
    "plt.title('Lomb-Scargle Data (20 fs timebins)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory = {}\n",
    "\n",
    "import h5py\n",
    "with h5py.File('cs2_diffsig_theory.mat','r') as f:\n",
    "    for name, data in f.items():\n",
    "        theory[name]=f[name].value\n",
    "\n",
    "# qAng - Dimensions (1, Nq) - q in inverse angstroms. \n",
    "# tt - Dimensions (1, nts) - Time vector.\n",
    "# tc - Dimensions (1,ntc) - Extended time vector for convoluted signal.\n",
    "# Wiam - Dimensions (Ntraj, Ntraj, Nq, nts) - Full scattering matrix (Imol + Iat), diagonal elements only.\n",
    "# Iat - Dimensions (1, Nq) - Atomic scattering term. \n",
    "# WW - Dimensions (Nq, nts) - Total scattering for Ehrenfest wavefunction (just the average over Ntraj as equal weights) - all trajectories. \n",
    "# WWc - Dimensions (Nq, nts) - Convoluted signal - all trajectories.\n",
    "# dW - Dimensions (Nq, nts) - Unconvoluted (raw) percentage difference signal - all trajectories.\n",
    "# dWc - Dimensions (Nq, nts) - Convoluted percentage difference signal - all trajectories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebin_theory(ts, ts_rebin, signal):\n",
    "    dt = np.diff(ts_rebin)\n",
    "    output = np.zeros((ts_rebin.size,Qs.size))\n",
    "    for i,t in enumerate(ts_rebin[:-1]):\n",
    "        tIdx = (ts>t)&(ts<t+dt[i])\n",
    "        output[i,:] = np.nanmean(signal[tIdx,:],axis=0)\n",
    "    return output\n",
    "\n",
    "Qs, ts = theory['qAng'][(theory['qAng']>0.5)&(theory['qAng']<8)].flatten(), theory['tc'].flatten()\n",
    "dWc = theory['dWc'][:,(theory['qAng']>0.5).flatten()&(theory['qAng']<8).flatten()]\n",
    "print Qs.shape, ts.shape, dWc.shape\n",
    "plt.figure()\n",
    "plt.pcolormesh(Qs,ts,dWc)\n",
    "plt.colorbar()\n",
    "plt.xlim([0.5,8])\n",
    "plt.show()\n",
    "\n",
    "tbin_size = 2\n",
    "ts_rebin = np.arange(np.min(ts),np.max(ts),tbin_size)\n",
    "signal_rebin = rebin_theory(ts,ts_rebin,dWc)\n",
    "# signal_rebin = gf_q(signal_rebin)\n",
    "# signal_rebin = gf_t(signal_rebin)\n",
    "plt.figure()\n",
    "plt.pcolormesh(Qs,ts_rebin,signal_rebin)\n",
    "plt.colorbar()\n",
    "plt.xlim([0.5,8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin,tmax = 200,1200\n",
    "ts = ts_rebin\n",
    "dWc = signal_rebin\n",
    "\n",
    "ts_transform = ts[(ts>tmin)&(ts<tmax)]\n",
    "dWc_transform = dWc[(ts>tmin)&(ts<tmax),:]\n",
    "dWc_norm = dWc - 1*np.mean(dWc_transform,axis=0)\n",
    "omegas = np.fft.fftshift(np.fft.fftfreq(n=ts_transform.size,d=np.mean(np.diff(ts_transform)/1000.)))*2*np.pi\n",
    "dw = np.mean(np.diff(omegas))\n",
    "omegas = omegas-dw/2\n",
    "QQ,WW = np.meshgrid(Qs,omegas)\n",
    "dWc_norm = dWc_transform - np.mean(dWc_transform,axis=0)\n",
    "fft_theory = np.fft.fftshift(np.fft.fft(dWc_norm,axis=0),axes=0)\n",
    "# fft_theory = gf_f(fft_theory)\n",
    "plt.figure()\n",
    "plt.pcolormesh(Qs,omegas,np.abs(WW)*np.abs(fft_theory))\n",
    "plt.colorbar()\n",
    "plt.xlim([0.5,8])\n",
    "plt.ylim([-np.min((np.max(omegas),400)),np.min((np.max(omegas),400))])\n",
    "plt.clim([0,1000])\n",
    "plt.xlabel(r'Q ($\\AA^{-1}$)')\n",
    "plt.ylabel(r'$\\omega$ (rad THz)')\n",
    "plt.title('CS2 FRXS Theory (%d fs timebins)' % tbin_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omegas_ls_theory, ls_theory = get_lombscargle(Qs,ts_transform,dWc_norm)\n",
    "# ls_theory = gf_ls(ls_theory)\n",
    "QQ_ls_theory,WW_ls_theory = np.meshgrid(Qs,omegas_ls_theory)\n",
    "plt.figure()\n",
    "plt.pcolormesh(Qs,omegas_ls_theory,np.abs(WW_ls_theory)*ls_theory)\n",
    "plt.ylim([-np.min((np.max(omegas_ls_theory),400)),np.min((np.max(omegas_ls_theory),400))])\n",
    "plt.xlim([0.5,8])\n",
    "plt.clim([0,10])\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'Q ($\\AA^{-1}$)')\n",
    "plt.ylabel(r'$\\omega$ (rad THz)')\n",
    "plt.title('CS2 Lomb-Scargle Theory (%d fs timebins)' % tbin_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that Lomb-Scargle gives nice results for simple trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0,1000,200)\n",
    "qs = np.linspace(1,4,100)\n",
    "f = 200\n",
    "a = 0.1\n",
    "def r(t,f,a):\n",
    "    return a*np.sin(f*t/1000)+2.5\n",
    "def r2(t,v,a):\n",
    "    return 2.5+v*t/1000\n",
    "QQ,TT = np.meshgrid(qs,ts)\n",
    "s1 = np.sinc(QQ*r2(TT,f/2,a)/np.pi)\n",
    "s2 = np.sinc(QQ*r(TT,1000,0.1))\n",
    "s = s1+s2\n",
    "plt.figure()\n",
    "plt.plot(ts,r2(ts,f,a))\n",
    "plt.title('Trajectory')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(QQ,TT,s)\n",
    "plt.colorbar()\n",
    "plt.title('S(Q,t)')\n",
    "plt.show()\n",
    "print s.shape,QQ.shape,TT.shape\n",
    "\n",
    "wws,ls_ss = get_lombscargle(qs,ts,s)\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(qs,wws,ls_ss)\n",
    "plt.colorbar()\n",
    "plt.clim([0,np.max(ls_ss)/10])\n",
    "plt.title('Lomb-Scargle')\n",
    "plt.show()\n",
    "\n",
    "omegas = np.fft.fftshift(np.fft.fftfreq(len(ts), d=np.mean(np.diff(ts))),axes=0)*1e3*2*np.pi\n",
    "ft = np.fft.fftshift(np.fft.fft(s-np.mean(s,axis=0),axis=0),axes=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(qs,omegas,np.abs(ft))\n",
    "plt.colorbar()\n",
    "plt.title('FFT')\n",
    "plt.clim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCLS-I py2",
   "language": "python",
   "name": "ana1-current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
