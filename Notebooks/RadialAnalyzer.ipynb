{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadialAnalyzer.ipynb\n",
    "This notebook will walk you through the basics of time-resolved analysis of X-ray scattering data at the CXI instrument at LCLS. It uses the preprocessed data generated for each shot over many runs, which has been stored in a `results` folder somewhere. Because it relies only on the preprocessed data, it can be used independently of the LCLS servers, assuming you have the data saved somewhere locally.\n",
    "\n",
    "This preprocessed data consists of individual shot readouts of many of the instruments available at CXI, including X-ray beam parameters, laser intensities, timetool correction values, and downsampled detector images. The steps in this notebook walk you through how we examine this data to monitor the health of the machine, reject outliers, and normalize and timebin the data to look for pump-probe signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic iPython command to enable plotting\n",
    "%matplotlib inline\n",
    "\n",
    "experiment='cxilu9218'\n",
    "pullDataFromUser='igabalsk' \n",
    "RESULTSPATH=('/cds/data/psdm/%s/%s/results/%s' % (experiment[0:3],experiment,pullDataFromUser)).strip()\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load point data from pkl (preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "def load_obj(filename, extension='.pkl'):\n",
    "    try:\n",
    "        if extension=='.h5':\n",
    "            output = {}\n",
    "            with h5py.File(filename + '.h5','r') as f:\n",
    "                for key in f.keys():\n",
    "                    output[key] = f[key][()]\n",
    "            print filename+\" remembered!\"\n",
    "            return output\n",
    "        else:\n",
    "            with open(filename + '.pkl', 'rb') as f:\n",
    "                print filename+\" remembered!\"\n",
    "                return pickle.load(f)\n",
    "    except IOError as e:\n",
    "        print \"IOError: Did you load the correct file? %s\" % filename\n",
    "        raise e\n",
    "\n",
    "def save_obj(obj, filename ):\n",
    "    with open(filename + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# These keys will be omitted from run combination and only read in for first runNumber\n",
    "exclude_keys = ['Qs','phis','bin_sizes','qphirois']\n",
    "\n",
    "def combineRuns(runNumbers, path=RESULTSPATH, prefix='all',extension='.pkl'):\n",
    "    '''\n",
    "    runNumbers : list of run numbers to combine\n",
    "    path : directory that contains point data .pkl files\n",
    "    prefix : one of ['all','filtered']. Choose 'all' for qphirois, 'filtered' for radial rois only\n",
    "    '''\n",
    "    detArrays = {}\n",
    "    for idx,run in enumerate(runNumbers):\n",
    "        if idx == 0:\n",
    "            detArrays = load_obj(path+'/%sData-run-%d' % (prefix,run),extension=extension)\n",
    "        else:\n",
    "            try:\n",
    "                detArrays0 = load_obj(path+'/%sData-run-%d' % (prefix,run),extension=extension)\n",
    "                for key in detArrays.keys():\n",
    "                    if key in exclude_keys:\n",
    "                        continue\n",
    "                    try:\n",
    "                        detArrays[key] = np.append( detArrays[key], detArrays0[key], axis=0 )\n",
    "                    except KeyError as ke:\n",
    "                        print('Dropping key %s since it is not in %d' % (key,run))\n",
    "                        detArrays.pop(key, None)\n",
    "            except IOError as ioe:\n",
    "                print(str(ioe))\n",
    "                continue\n",
    "    return detArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runNumbers = [45,46,47,48,49,50,51,52,53,54,55]\n",
    "runNumbersRange = '[%d - %d]' % (min(runNumbers),max(runNumbers))\n",
    "\n",
    "detArrays = combineRuns(runNumbers,prefix='filtered',extension='.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 0: Taking a first look at the data\n",
    "The `combineRuns()` function returns a Python dictionary object. Dictionary objects contain keys (which can be strings or any other hashable object) and values (which can be single numbers or entire arrays, or any other Python object). For us, the `detArrays` dictionary has just strings for keys which specify the name of the datasets and Numpy arrays for the values. To get a sense of the types of data available to us, let's take a look at the names of the datasets and the shapes of the Numpy arrays in `detArrays`.\n",
    "\n",
    "**TASK:** Write a piece of code that prints out all of the keys in `detArrays` and the shape of the array associated with each key. Based on the output, figure out how many shots are in the combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE: Histogram X-ray energies\n",
    "On each LCLS shot, a whole host of values are read out from the various instruments and saved to disk. The data from instruments that read out a single value on each shot are referred to as \"point data.\" We monitor these point data during beamtime to track the health of the machine. Mostly this consists of histogramming the point data values for individual runs and comparing the distribution of values to an expected distribution.\n",
    "\n",
    "Here, let's take a look at one of the most important point data, the pulse energy of the X-ray beam. The `detArrays` key for this is `'xrayEnergy'` and the value is read out in milliJoules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(detArrays['xrayEnergy'][~np.isnan(detArrays['xrayEnergy'])],bins=100)\n",
    "plt.xlabel('xrayEnergy (mJ)')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Runs %s' % runNumbersRange)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE: Radial rois vs. Q\n",
    "Now let's take a look at the actual detector images. We downsample the (large) detector images by identifying Regions Of Interest (ROIs) and averaging the pixel values in each ROI on each shot. Here, we have used 100 bins in $Q$, such that the $i^{th}$ ROI is the average of all pixels that fall between $Q_i$ and $Q_i+dQ$.\n",
    "\n",
    "In order to verify that we're looking at the molecule we think we are, let's plot the average scattering pattern on the detector as a function of $Q$ and then comparing to the signal we expect from theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = detArrays['Qs']\n",
    "print Q.shape\n",
    "\n",
    "plt.figure()\n",
    "meanSig = np.nanmean(detArrays['rois'],axis=0)\n",
    "plt.plot(Q,Q*meanSig)\n",
    "plt.xlabel('Q')\n",
    "plt.ylabel('Q * I(Q)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to the theoretical signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def normalizedPlot(x,y,s=1,**kwargs):\n",
    "    plt.plot(x, y/np.nanmean(y[(x>2)&(x<2.5)])*s,**kwargs)\n",
    "\n",
    "def loadfile(filename):\n",
    "    mol = {}\n",
    "    with h5py.File(filename,'r') as f:\n",
    "        for name, data in f.items():\n",
    "            mol[name]=f[name][()]\n",
    "    return mol\n",
    "\n",
    "molecule = 'CS2'\n",
    "mol = loadfile('/cds/home/i/igabalsk/xray/diffraction_simulation/isotropic_scattering_%s.h5' % molecule)\n",
    "\n",
    "interpolatedMol = np.interp(Q, mol['QQ_1d'], mol['isotropic_scattering_1d'])\n",
    "\n",
    "normalizedPlot(Q,Q*meanSig,s=1)\n",
    "normalizedPlot(Q,Q*interpolatedMol)\n",
    "plt.xlabel('Q')\n",
    "plt.ylabel('Q * I(Q)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that we seem to be seeing an excess of scattering at high $Q$. Our working explanation for this at the moment is that this excess scattering into large angles is from Compton scattering. Our current theory only takes elastic Thomson scattering into account and neglects inelastic Compton scattering, but as the X-ray energy is increased this effect will become more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE: Histogram of timetool pixel position\n",
    "The timetool is the instrument that gives you the time delay between the laser and X-rays on a shot-by-shot basis. In this instrument, the X-rays are overlapped with a broad chirped laser pulse and sent through a material that attenuates the laser. The arrival of the X-rays abruptly increases the absorption of the attenuator, and thus the back end of the laser pulse is attenuated more. Since the pulse is chirped, that means there will be an edge in the spectrum of the transmitted chirped pulse that can be measured in a spectrometer. The edge position in the spectrum is directly related to the arrival time of the X-rays relative to the laser pulse. \n",
    "\n",
    "The online analysis of the timetool performs a fit for the edge location, width, and amplitude. These are all written out as point data, and we use these extensively to both diagnose problems during beamtime and get sufficient time resolution in our post-analysis. Let's look a these timetool values.\n",
    "\n",
    "The first example is the position of the edge on the spectrometer detector. This is read out in raw pixels and must eventually be calibrated to convert to time delay. The `detArrays` key for this value is `'ttfltpos'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(detArrays['ttfltpos'][np.abs(detArrays['ttfltpos'])<2000],bins=2000,label='TT Position');\n",
    "plt.xlim([0,1000])\n",
    "plt.ylim([0,9e3])\n",
    "plt.ylabel('counts');\n",
    "plt.xlabel('pixel pos');\n",
    "plt.title('Runs %s'%runNumbersRange)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1: Histogram of the FWHM of the fitted timetool edge\n",
    "Note that in the above plot, there is a central peak but also some side lobes. These side lobes sometimes result from an X-ray shot being dropped or from some other malfunction in the apparatus. This causes the timetool to fit an edge location to a garbage spectrum. These bad shots must be filtered out.\n",
    "\n",
    "In addition to fitting the edge position on the timetool, the algorithm also fits the edge width. This edge width is saved under the `'ttfltposfwhm'` key. An edge width that is out of the ordinary could indicate that the apparatus malfulctioned and the fit failed, so we can filter our shots based on this key.\n",
    "\n",
    "**TASK:** Generate a histogram of the timetool edge width, and suggest a range of good values for the width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2: Histogram of the amplitude of the timetool signal\n",
    "Similarly to the edge width, the edge amplitude can also be a useful indicator of whether or not the timetool fit was good. See if you can figure out which `detArrays` key corresponds to this dataset.\n",
    "\n",
    "**TASK:** Generate a histogram of the timetool edge amplitude, and suggest a range of good values. (Hint: you may need to adjust the y-axis to see the structure of this plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3: Laser on/laser off shots\n",
    "We do not pump the sample with the laser on every shot. We mix in a certain fraction of \"laser off\" shots using a tool creatively named the \"goose trigger\" (think the trigger going \"duck, duck, duck, goose, ...\" to the laser). This is done to take regular static detector images to monitor if we have a changing background or conditions in the sample chamber. We can then use these laser off shots to subtract the static scattering pattern from the shots where the laser was on and the sample was dynamic. \n",
    "\n",
    "The `detArrays` key that indicates whether the laser was on is `'laserOn'`. There are also other keys which would seem to measure the same thing, but that is an artifact from the beamtime where the event codes for laser on would be written to one address or another. The keys for the UV laser intensity are `'uvint0'` and `'uvint1'`, corresponding to two separate laser diodes.\n",
    "\n",
    "**TASK:** Make a single plot that histograms the laser intensity values separately for laser on and laser off shots. Try it for each of the UV laser diodes. Does one of the diodes tell you which shots were on/off?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 4: Outlier rejection\n",
    "As the last few tasks have illustrated, not every LCLS shot translates into a good data point for time-resolved analysis. Some shots purposely do not have a pump laser pulse, and some shots are untrustworthy due to random apparatus malfunctions. We need to pick out a subset of the total shots that we think contain good information based on the point data values. We can do this by building up a boolean index that indicates whether we want to keep a particular shot or throw it away.\n",
    "\n",
    "Let's filter on a list of point data values:\n",
    "- X-ray Energy\n",
    "- X-ray On\n",
    "- Laser On\n",
    "- Timetool Position\n",
    "- Timetool FWHM\n",
    "- Timetool Amplitude\n",
    "\n",
    "We've already decided on some good ranges for most of these values. I'll get you started with the X-ray Energy and X-ray On filters, and you can go from there\n",
    "\n",
    "**TASK:** Using the starter code below, build a boolean index array called `goodIdx` that indicates the shots we want to keep. After each additional filter, print out the fraction of good shots still left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code\n",
    "goodIdx = ( detArrays['xrayEnergy']>.6 )\n",
    "goodIdx = goodIdx & (detArrays['xrayOn'].astype(bool))\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK: Histogram of the timetool positions after outlier rejection\n",
    "Does this look like a reasonable distribution of timetool values, based on all the filtering you've done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(detArrays['ttfltpos'][goodIdx],bins=500);\n",
    "plt.xlim([0,2000])\n",
    "plt.xlabel('fltpos')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE: Timebinning the shots\n",
    "Now that we have rejected outliers, we are ready to timebin our shots. This is the crucial step in any time-resolved analysis since it allows us to get good enough X-ray counting statistics at each time delay to infer the specific geometry of the molecule.\n",
    "\n",
    "This part contains a fair amount of logic that is specific to the apparatus and the timetool calibration, so it'll just be an example. However, make sure you understand this part, and don't be afraid to ask lots of questions.\n",
    "\n",
    "To summarize, there are two crucial quantities that together determine the shot-by-shot time delay: `'stageencoder'` and `'ttfltpos'`. We've already seen the timetool edge position quantity earlier. The `'stageencoder'` value corresponds to a delay stage position in mm on the pump laser. A larger value on this delay stage means the laser is getting more delayed with respect to the X-rays, so a smaller pump-probe delay. The timetool has its own delay stage that keeps the timetool edge roughly centered on the spectrometer, so the sum of the delays measured on the stage and the timetool gives the shot-by-shot pump-probe delay.\n",
    "\n",
    "Let's first just look at the nominal time delays defined solely by the `'stageencoder'` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = detArrays['stageencoder'][goodIdx]\n",
    "goodRois = detArrays['rois'][goodIdx,:]\n",
    "offIdx = ~detArrays['laserOn'].astype(bool)\n",
    "offRois =  detArrays['rois'][offIdx,:]\n",
    "\n",
    "pos0 = 56.35 # LU92 nominal time zero\n",
    "posfs = -2*(pos-pos0) / (3e-4) # 3e-4 is speed of light in mm/fs\n",
    "unpos = np.sort(np.unique( np.round(pos,decimals=2)))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(unpos)\n",
    "plt.ylabel('unique delays (mm)')\n",
    "plt.xlabel('idx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL: Weight individual shots by various quantities\n",
    "Here we have the opportunity to weight each shot by particular quantities such as the X-ray energy. For now we will not weight individual shots by anything for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeWeights(rois, goodIdx):\n",
    "    goodrois = rois[goodIdx,:]\n",
    "    \n",
    "    gsum = np.nansum(goodrois,-1)\n",
    "    groiN = ((goodrois.T)/(gsum.T)).T\n",
    "    \n",
    "    weights = np.zeros_like(goodrois)\n",
    "    for idx,roi in enumerate(groiN):\n",
    "        weights[idx,:] = groiN[idx,:]\n",
    "        \n",
    "    return weights\n",
    "\n",
    "weightMe = makeWeights(detArrays['rois'], goodIdx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE: Rebin the shot-by-shot data into time bins (without timetool correction)\n",
    "We need to create timebins into which we can then place individual shots. As a first pass, let's ignore the timetool correction, and just use the nominal time delays based on delay stage position as the centers of our timebins.\n",
    "\n",
    "Remember that earlier, we created a list of unique delay stage positions by rounding the `'stageencoder'` values to two decimal places and finding the unique values. We can now find the bin edges by picking the midpoints between adjacent centers individually.\n",
    "\n",
    "Once we have the bins and weights, we can efficiently timebin the shots with the `for` loop at the bottom. The way we do this is that for each radial (or Q) bin, we histogram the total number of shots in each timebin, where each shot is weighted by the number of X-rays that scattered into the Q bin on that shot. We then normalize each timebin by the number of shots in each timebin. \n",
    "\n",
    "Take some time to convince yourself that this indeed gives us the timebinned X-rays in each Q bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBinsFromCenters(centers):\n",
    "    bins = []\n",
    "    nc = centers.size\n",
    "    for idx,c in enumerate(centers):\n",
    "        if idx == 0:\n",
    "            dc = np.abs( c - centers[idx+1])/2.\n",
    "            bins.append(c-dc)\n",
    "            bins.append(c+dc)\n",
    "        elif idx == nc-1:\n",
    "            dc = np.abs( c - centers[idx-1])/2.\n",
    "            bins.append(c+dc)\n",
    "        else:\n",
    "            dc = np.abs( c - centers[idx+1])/2.\n",
    "            bins.append(c+dc)\n",
    "    return np.array(bins)\n",
    "\n",
    "# Find the bin centers and edges using the function above\n",
    "bins = createBinsFromCenters( unpos )\n",
    "centers = unpos\n",
    "centersfs = 2*np.flip(np.array(centers)-pos0) / (3e-4) # delay in fs is negative of delay stage position\n",
    "nb = bins.size\n",
    "nr = goodRois.shape[1]\n",
    "\n",
    "radialHist = np.zeros((nb-1,nr))\n",
    "radialAvg = np.zeros((nb-1,nr))\n",
    "\n",
    "# This is where the magic happens\n",
    "counts,edges = np.histogram( pos,bins=bins)\n",
    "for ir in range(nr):\n",
    "\n",
    "    radialHist[:,ir],edges = np.histogram( pos,bins=bins, weights=weightMe[:,ir])\n",
    "    radialAvg[:,ir] = radialHist[:,ir] / counts\n",
    "    \n",
    "# Plot the number of shots in each timebin    \n",
    "plt.figure()\n",
    "plt.plot(centers, counts,'.-')\n",
    "plt.xlabel('delay pos')\n",
    "plt.ylabel('counts')\n",
    "plt.title('Counts in each timebin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE: Update cutoff to reflect bad points above\n",
    "Note that some bins have very few counts in them. This comes from the fact that when the delay stage moves between positions, the X-rays are still firing. Since the instantaneous position of the delay stage is read out on every shot, this means that there will be timebins in between the delays we want that have very few shots. We need to get rid of these timebins to visualize our data.\n",
    "\n",
    "Based on the plot above, any cutoff above 100 counts should do the trick. We have chosen 1000 as our cutoff for the number of shots in our timebin. Since we're still using relatively large timebins with no timetool correction, this just serves to get rid of the bad points mentioned above. However, once we start timetool correcting, the counts cutoff will become a meaningful decision we need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 1000\n",
    "plot2d= (radialAvg)[counts>cutoff,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE: Plotting the time-resolved signal\n",
    "You've made it! We're ready to plot the difference signal between laser-off and laser-on shots.\n",
    "\n",
    "We're doing a few things here:\n",
    "- Gaussian filtering in Q to smooth out shot noise in Q bins\n",
    "- Subtracting the laser-off shots (\"goose\" shots) from all shots\n",
    "- Selecting a scale for our colorbar to estimate the percent difference (this will give us the excitation fraction)\n",
    "\n",
    "Familiarize yourself with the mechanics here. We will do this again as an exercise with the timetool-corrected dataset, but the mechanics are otherwise the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2d= (radialAvg)[counts>cutoff,:]\n",
    "rcent = centers[counts>cutoff]\n",
    "rcentfs = -2*(rcent-pos0) / (3e-4)\n",
    "roio = np.nansum(offRois,-1)\n",
    "subAll = np.mean(((offRois.T)/(roio.T)).T,0) # goose subtraction\n",
    "\n",
    "gf = lambda x: gaussian_filter1d(x,4,axis=-1)\n",
    "plot2d = (gf(plot2d)-gf(subAll)) / gf(subAll)\n",
    "plot2d = gaussian_filter1d(plot2d,1,axis=0)\n",
    "\n",
    "dv = 4e-3\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.pcolormesh(Q, rcentfs, plot2d, vmin = -dv, vmax = dv )\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(length=5,width=2,labelsize=15)\n",
    "plt.xlabel('Q (iA)',fontsize=20)\n",
    "plt.ylabel('delay (fs)',fontsize=20)\n",
    "plt.title('(I - I(off))/I(off)',fontsize=20)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both',length=5,width=2,labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the same data as above, but now with each timebin getting its own line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "for idx,delay in enumerate(rcentfs):\n",
    "    plt.plot(Q, plot2d[idx,:], label='%.2f ps'% (delay/1000),linewidth=2 )\n",
    "plt.ylim([-.015,.015])\n",
    "plt.xlabel('Q',fontsize=20)\n",
    "plt.ylabel('dI/I',fontsize=20)\n",
    "plt.title('Runs %s'%runNumbersRange,fontsize=20)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both',length=5,width=2,labelsize=15)\n",
    "plt.legend(fontsize=15,bbox_to_anchor=(1, 1), loc='upper left',ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE: Timetool correction\n",
    "We've looked at timebins using the nominal delays between the pump and probe. However, the X-ray laser has significant jitter in its timing, so to get fine shot-by-shot timing we must use the timetool correction. We do this using the calibrated relationship between `'ttfltpos'` and the actual time delay.\n",
    "\n",
    "We previously performed a quadratic fit to the calibration run that gave us fit coefficients, shown below in `ttpoly`. We now take the nominal time delays and add back in the timetool correction using the `ttcorr()` function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttpoly = [2.95684259e-06, -1.43969413e-03] # LV11\n",
    "ttpoly = [2.95684259e-06, -1.43969413e-03] # LU92\n",
    "ttpoly = [-9.36209506e-10,  3.76314033e-06, -1.63476074e-03] # LU92 quadratic fit\n",
    "def ttcorr(ttpos,ttpoly):\n",
    "    return ttpoly[0]*ttpos**2+ttpoly[1]*ttpos+ttpoly[2] # quadratic fit to previous calibration\n",
    "\n",
    "ttpos = detArrays['ttfltpos'][goodIdx]\n",
    "truepos = -2*(pos-pos0) / (3e-4)  - ttcorr(ttpos,ttpoly)*1.0e6 # convert calibration from ns to fs\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.hist(truepos,bins=1000)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both',length=5,width=2,labelsize=15)\n",
    "plt.xlabel('pump-probe delay (fs)',fontsize=20)\n",
    "plt.ylabel('frames in timebin',fontsize=20)\n",
    "plt.title('pump-probe delay histogram')\n",
    "plt.title('Day 1: Runs %s'%runNumbersRange,fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 5: Selecting finer timebins\n",
    "Let's now select a set of much finer timebins that are evenly spaced in time. We can use much of the same infrastructure as when we were timebinning based on coarse nominal delays. \n",
    "\n",
    "**TASK:** Based on the histogram of counts in the very fine timebins in the plot above, choose a range of time delays and a timebin size. Implement this set of timebin centers as a Numpy array called `usecenters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecenters =  # this is a Numpy array of timebin centers\n",
    "bins = createBinsFromCenters( np.array(usecenters) )\n",
    "centersfs = usecenters\n",
    "\n",
    "nb=bins.size\n",
    "\n",
    "radialHist = np.zeros((nb-1,nr))\n",
    "radialAvg = np.zeros((nb-1,nr))\n",
    "counts,edges = np.histogram( truepos,bins=bins)\n",
    "for ir in range(nr):\n",
    "    radialHist[:,ir],edges = np.histogram( truepos,bins=bins, weights=weightMe[:,ir])\n",
    "    radialAvg[:,ir] = radialHist[:,ir] / counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 6: Choosing a new counts cutoff\n",
    "We now have MUCH finer timebins than we did before. Because of this, the number of counts in each timebin will be much lower. We need to choose a good counts cutoff to go with these new timebins.\n",
    "\n",
    "There are two competing interests here:\n",
    "- Keeping more timebins allows us to see longer time delays, and potentially more long-time physical processes\n",
    "- Restricting ourselves to bins with many counts improves the shot noise in each bin, reducing our noise in the bins we do keep\n",
    "\n",
    "It is up to us to make a judgement call on this. There are no rules written in stone here.\n",
    "\n",
    "**TASK:** Choose a new cutoff that reflects your best guess based on the two competing interests mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0 # Adjust this based on your best judgement\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(centersfs, counts,'.-',linewidth=2,markersize=10)\n",
    "plt.ylim([cutoff,np.max(counts)+500])\n",
    "plt.xlabel('binned delay (fs)',fontsize=20)\n",
    "plt.ylabel('counts in bin',fontsize=20)\n",
    "plt.title('Day 1: Runs %s'%runNumbersRange,fontsize=20)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both',length=5,width=2,labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 7: Putting it all together\n",
    "We are now ready to look at our timetool-corrected difference signal. \n",
    "\n",
    "**TASK:** Write code to plot the timetool-corrected difference signal using your fine timebins defined above.\n",
    "\n",
    "*Hint: This code should be virtually identical to the code used to generate the difference signal plot using nominal timebins.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCLS-I py2",
   "language": "python",
   "name": "ana1-current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
